---
layout: default
permalink: /index.html
---

* Instructor  
    Dr. Nicholas Dronen  
    Department of Computer Science  
    Engineering Center South Tower 121  
    dronen@colorado.edu  
    Office hours: Wednesday 3:20-4:20  
* Teaching Assistant  
     Amruta Rajopadhye  
     amruta.rajopadhye@colorado.edu  
     Engineering Center - TBD  
     Office hours: TBD  
* Grader  
    TBD  
    TBD@colorado.edu  

Deep Learning is a field of rapid change and, to date, some stunning accomplishments. It has changed the landscape of computer science and machine learning in the decade since [Geoff Hinton presented unsupervised, layer-wise pre-training](https://www.youtube.com/watch?v=AyzOUbkUf3M) to an eager audience at Google. The elements of deep learning as it exists today are

* Neural networks, for learning
* Automatic differentiation, for reliably programming neural networks
* Large datasets, for training neural networks to perform some task
* Specialized hardware, for expediting the training and inference processes

Neural networks written with auto-differentiation software and trained on large datasets using specialized hardware -- that, in a nutshell, is deep learning.

In this course, I will emphasize neural networks and automatic differentiation. By the end of the semester, you should have
* mastered, in code and on paper, forward and backward propagation in feed-forward, convolutional, and recurrent networks,
* created your own auto-differentiation software for implementing feed-forward, convolutional, and recurrent networks,
* written and trained your own feed-forward, convolutional, and recurrent networks using your auto-differentiation software,
* and implemented several recent optimization algorithms for training neural networks.

If you master this material, you will have a firm foundation on which you base subsequent work in deep learning, whether in academia or industry. In your programming assignments, you will use small networks, simple, small datasets, and your personal computer, because large networks and datasets can distract the beginner from focusing on principles, and because training small neural networks on small datasets can be done quickly on today’s general-purpose CPUs, thereby allowing you to iterate quickly. That said, I will not altogether ignore the two other elements of deep learning. I will devote some time to datasets for learning common tasks in various fields, such as natural language processing, computer vision, and speech recognition. I will also introduce you to the computer architecture of various deep learning hardware — from expensive, power-hungry devices for datacenter environments to small, low-power devices for the “edge”.

## [Policies](/policies.html)

## [Assignments](/assignments.html)

## [Schedule](/schedule.html)

## [Resources](/resources.html)
